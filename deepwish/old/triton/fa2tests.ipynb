{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import triton\nprint(triton.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T01:06:08.843634Z","iopub.execute_input":"2025-06-21T01:06:08.844107Z","iopub.status.idle":"2025-06-21T01:06:09.683830Z","shell.execute_reply.started":"2025-06-21T01:06:08.844080Z","shell.execute_reply":"2025-06-21T01:06:09.683278Z"}},"outputs":[{"name":"stdout","text":"3.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T01:06:09.684332Z","iopub.execute_input":"2025-06-21T01:06:09.684500Z","iopub.status.idle":"2025-06-21T01:06:14.822003Z","shell.execute_reply.started":"2025-06-21T01:06:09.684485Z","shell.execute_reply":"2025-06-21T01:06:14.821466Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport triton\nimport triton.language as tl\nimport triton.testing\nDEVICE = \"cuda\"\n\n@triton.jit\n# Block-wise attention forward with explicit diagonal flag\ndef attention_forward_block(acc, l_i, m_i, q,  \\\n                            K_block_ptr, V_block_ptr,  \\\n                            start_m, qk_scale,  \\\n                            BLOCK_M: tl.constexpr, HEAD_DIM: tl.constexpr, BLOCK_N: tl.constexpr,  \\\n                            ON_DIAGONAL: tl.constexpr, offs_m: tl.constexpr, offs_n: tl.constexpr,  \\\n                            SEQ_LEN: tl.constexpr, use_fp8: tl.constexpr):\n    # determine block range: off-diagonal vs diagonal\n    if not ON_DIAGONAL:\n        lo, hi = 0, start_m * BLOCK_M\n    else:\n        lo, hi = start_m * BLOCK_M, (start_m + 1) * BLOCK_M\n        lo = tl.multiple_of(lo, BLOCK_M)\n\n    K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n    # need this to be sequential, so no race condition.\n    for start_n in range(lo, hi, BLOCK_N):\n        start_n = tl.multiple_of(start_n, BLOCK_N)\n        k = tl.load(K_block_ptr)\n        qk = tl.dot(q, k)\n        if ON_DIAGONAL:\n            mask = offs_m[:, None] >= (start_n + offs_n[None, :])\n            qk = qk * qk_scale + tl.where(mask, 0, -1.0e6)\n            m_ij = tl.maximum(m_i, tl.max(qk, 1))\n            qk -= m_ij[:, None]\n        else:\n            m_ij = tl.maximum(m_i, tl.max(qk, 1) * qk_scale)\n            qk = qk * qk_scale - m_ij[:, None]\n        p = tl.math.exp2(qk)\n        l_ij = tl.sum(p, 1)\n        alpha = tl.math.exp2(m_i - m_ij)\n        l_i = l_i * alpha + l_ij\n        acc = acc * alpha[:, None]\n\n        v = tl.load(V_block_ptr)\n        if use_fp8:\n            p = p.to(tl.float8e5)\n        else:\n            p = p.to(tl.float16)\n        acc = tl.dot(p, v, acc)\n\n        m_i = m_ij\n        V_block_ptr = tl.advance(V_block_ptr, (BLOCK_N, 0))\n        K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_N))\n    return acc, l_i, m_i\n\n@triton.jit\ndef attention_forward(Q, K, V, sm_scale, M, Out,  \\\n                      stride_qz, stride_qh, stride_qm, stride_qk,  \\\n                      stride_kz, stride_kh, stride_kn, stride_kk,  \\\n                      stride_vz, stride_vh, stride_vk, stride_vn,  \\\n                      stride_oz, stride_oh, stride_om, stride_on,  \\\n                      BATCH_SIZE, NUM_HEADS, SEQ_LEN,  \\\n                      HEAD_DIM: tl.constexpr,  \\\n                      BLOCK_M: tl.constexpr,  \\\n                      BLOCK_N: tl.constexpr):\n    tl.static_assert(BLOCK_N <= HEAD_DIM)\n    start_m = tl.program_id(0)\n    off_hz = tl.program_id(1)\n    batch_id = off_hz // NUM_HEADS\n    head_id = off_hz % NUM_HEADS\n    qvk_offset = batch_id.to(tl.int64) * stride_qz + head_id.to(tl.int64) * stride_qh\n\n    Q_block_ptr = tl.make_block_ptr(\n        base=Q + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_qm, stride_qk),\n        offsets=(start_m * BLOCK_M, 0),\n        block_shape=(BLOCK_M, HEAD_DIM),\n        order=(1, 0),\n    )\n    v_order: tl.constexpr = (0, 1) if V.dtype.element_ty == tl.float8e5 else (1, 0)\n    V_block_ptr = tl.make_block_ptr(\n        base=V + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_vk, stride_vn),\n        offsets=(0, 0),\n        block_shape=(BLOCK_N, HEAD_DIM),\n        order=v_order,\n    )\n    K_block_ptr = tl.make_block_ptr(\n        base=K + qvk_offset,\n        shape=(HEAD_DIM, SEQ_LEN),\n        strides=(stride_kk, stride_kn),\n        offsets=(0, 0),\n        block_shape=(HEAD_DIM, BLOCK_N),\n        order=(0, 1),\n    )\n    O_block_ptr = tl.make_block_ptr(\n        base=Out + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_om, stride_on),\n        offsets=(start_m * BLOCK_M, 0),\n        block_shape=(BLOCK_M, HEAD_DIM),\n        order=(1, 0),\n    )\n    offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = tl.arange(0, BLOCK_N)\n    m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\n    l_i = tl.zeros([BLOCK_M], dtype=tl.float32) + 1.0\n    acc = tl.zeros([BLOCK_M, HEAD_DIM], dtype=tl.float32)\n    qk_scale = sm_scale\n    qk_scale *= 1.44269504\n    q = tl.load(Q_block_ptr)\n    # process off-diagonal blocks\n    acc, l_i, m_i = attention_forward_block(acc, l_i, m_i, q,\n                                            K_block_ptr, V_block_ptr,\n                                            start_m, qk_scale,\n                                            BLOCK_M, HEAD_DIM, BLOCK_N,\n                                            False, offs_m, offs_n, SEQ_LEN,\n                                            V.dtype.element_ty == tl.float8e5)\n    # process diagonal block\n    acc, l_i, m_i = attention_forward_block(acc, l_i, m_i, q,\n                                            K_block_ptr, V_block_ptr,\n                                            start_m, qk_scale,\n                                            BLOCK_M, HEAD_DIM, BLOCK_N,\n                                            True, offs_m, offs_n, SEQ_LEN,\n                                            V.dtype.element_ty == tl.float8e5)\n    m_i += tl.math.log2(l_i)\n    acc = acc / l_i[:, None]\n    m_ptrs = M + off_hz * SEQ_LEN + offs_m\n    tl.store(m_ptrs, m_i)\n    tl.store(O_block_ptr, acc.to(Out.type.element_ty))\n\n@triton.jit\ndef _attn_bwd_dkdv(dk, dv, Q, k, v, sm_scale, O, DO, M, stride_tok, stride_d, H, N_CTX, \\\n                   BLOCK_M1: tl.constexpr, BLOCK_N1: tl.constexpr, HEAD_DIM: tl.constexpr, \\\n                   start_n, start_m, num_steps, MASK: tl.constexpr):\n    offs_m = start_m + tl.arange(0, BLOCK_M1)\n    offs_n = start_n + tl.arange(0, BLOCK_N1)\n    offs_k = tl.arange(0, HEAD_DIM)\n    qT_ptrs = Q + offs_m[None, :] * stride_tok + offs_k[:, None] * stride_d\n    do_ptrs = DO + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d\n    o_ptrs  =  O + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d\n    tl.static_assert(BLOCK_N1 % BLOCK_M1 == 0)\n    curr_m = start_m\n    step_m = BLOCK_M1\n    for blk_idx in range(num_steps):\n        qT = tl.load(qT_ptrs)\n        offs_m = curr_m + tl.arange(0, BLOCK_M1)\n        m = tl.load(M + offs_m)\n        qkT = tl.dot(k, qT)\n        pT = tl.math.exp2(qkT - m[None, :])\n        if MASK:\n            mask = (offs_m[None, :] >= offs_n[:, None])\n            pT = tl.where(mask, pT, 0.0)\n        do = tl.load(do_ptrs)\n        o  = tl.load(o_ptrs)\n        delta = tl.sum(o * do, axis=1)\n        ppT = pT.to(tl.float16)\n        dv += tl.dot(ppT, do)\n        dpT = tl.dot(v, tl.trans(do)).to(tl.float32)\n        dsT = pT * (dpT - delta[None, :])\n        dsT = dsT.to(tl.float16)\n        dk += tl.dot(dsT, tl.trans(qT))\n        curr_m += step_m\n        qT_ptrs += step_m * stride_tok\n        do_ptrs += step_m * stride_tok\n        o_ptrs  += step_m * stride_tok\n    return dk, dv\n\n@triton.jit\ndef _attn_bwd_dq(dq, q, K, V, O, do, m, stride_tok, stride_d, H, N_CTX, \\\n                 BLOCK_M2: tl.constexpr, BLOCK_N2: tl.constexpr, HEAD_DIM: tl.constexpr, \\\n                 start_m, start_n, num_steps, MASK: tl.constexpr):\n    offs_m = start_m + tl.arange(0, BLOCK_M2)\n    offs_n = start_n + tl.arange(0, BLOCK_N2)\n    offs_k = tl.arange(0, HEAD_DIM)\n    kT_ptrs = K + offs_n[None, :] * stride_tok + offs_k[:, None] * stride_d\n    vT_ptrs = V + offs_n[None, :] * stride_tok + offs_k[:, None] * stride_d\n    o   = tl.load(O + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d)\n    delta = tl.sum(o * do, axis=1)\n    tl.static_assert(BLOCK_M2 % BLOCK_N2 == 0)\n    curr_n = start_n\n    step_n = BLOCK_N2\n    for blk_idx in range(num_steps):\n        kT = tl.load(kT_ptrs)\n        vT = tl.load(vT_ptrs)\n        qk = tl.dot(q, kT)\n        p = tl.math.exp2(qk - m)\n        if MASK:\n            offs_n_current = curr_n + tl.arange(0, BLOCK_N2)\n            mask = (offs_m[:, None] >= offs_n_current[None, :])\n            p = tl.where(mask, p, 0.0)\n        dp = tl.dot(do, vT).to(tl.float32)\n        ds = p * (dp - delta[:, None])\n        ds = ds.to(tl.float16)\n        dq += tl.dot(ds, tl.trans(kT))\n        curr_n += step_n\n        kT_ptrs += step_n * stride_tok\n        vT_ptrs += step_n * stride_tok\n    return dq\n\n@triton.jit\ndef _attn_bwd(Q, K, V, sm_scale,  \\\n              O, DO,  \\\n              DQ, DK, DV,  \\\n              M,  \n              stride_z, stride_h, stride_tok, stride_d,  \\\n              H, N_CTX,  \\\n              BLOCK_M1: tl.constexpr,  \\\n              BLOCK_N1: tl.constexpr,  \\\n              BLOCK_M2: tl.constexpr,  \\\n              BLOCK_N2: tl.constexpr,  \\\n              BLK_SLICE_FACTOR: tl.constexpr,  \\\n              HEAD_DIM: tl.constexpr):\n    LN2: tl.constexpr = 0.6931471824645996\n    bhid = tl.program_id(2)\n    off_chz = (bhid * N_CTX).to(tl.int64)\n    adj = (stride_h * (bhid % H) + stride_z * (bhid // H)).to(tl.int64)\n    pid = tl.program_id(0)\n    Q += adj\n    K += adj\n    V += adj\n    O += adj\n    DO += adj\n    DQ += adj\n    DK += adj\n    DV += adj\n    M += off_chz\n    offs_k = tl.arange(0, HEAD_DIM)\n    start_n = pid * BLOCK_N1\n    start_m = start_n\n    MASK_BLOCK_M1: tl.constexpr = BLOCK_M1 // BLK_SLICE_FACTOR\n    offs_n = start_n + tl.arange(0, BLOCK_N1)\n    dv = tl.zeros([BLOCK_N1, HEAD_DIM], dtype=tl.float32)\n    dk = tl.zeros([BLOCK_N1, HEAD_DIM], dtype=tl.float32)\n    k = tl.load(K + offs_n[:, None] * stride_tok + offs_k[None, :] * stride_d)\n    v = tl.load(V + offs_n[:, None] * stride_tok + offs_k[None, :] * stride_d)\n    num_steps = BLOCK_N1 // MASK_BLOCK_M1\n    dk, dv = _attn_bwd_dkdv(dk, dv, Q, k, v, sm_scale, O, DO, M, \\\n                            stride_tok, stride_d, H, N_CTX, \\\n                            MASK_BLOCK_M1, BLOCK_N1, HEAD_DIM, \\\n                            start_n, start_m, num_steps, MASK=True)\n    start_m += num_steps * MASK_BLOCK_M1\n    num_steps = (N_CTX - start_m) // BLOCK_M1\n    dk, dv = _attn_bwd_dkdv(dk, dv, Q, k, v, sm_scale, O, DO, M, \\\n                            stride_tok, stride_d, H, N_CTX, \\\n                            BLOCK_M1, BLOCK_N1, HEAD_DIM, \\\n                            start_n, start_m, num_steps, MASK=False)\n    dv_ptrs = DV + offs_n[:, None] * stride_tok + offs_k[None, :] * stride_d\n    tl.store(dv_ptrs, dv)\n    dk *= sm_scale\n    dk_ptrs = DK + offs_n[:, None] * stride_tok + offs_k[None, :] * stride_d\n    tl.store(dk_ptrs, dk)\n    start_m = pid * BLOCK_M2\n    end_n = start_m + BLOCK_M2\n    MASK_BLOCK_N2: tl.constexpr = BLOCK_N2 // BLK_SLICE_FACTOR\n    offs_m = start_m + tl.arange(0, BLOCK_M2)\n    q = tl.load(Q + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d)\n    dq = tl.zeros([BLOCK_M2, HEAD_DIM], dtype=tl.float32)\n    do = tl.load(DO + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d)\n    m = tl.load(M + offs_m)\n    m = m[:, None]\n    num_steps = BLOCK_M2 // MASK_BLOCK_N2\n    dq = _attn_bwd_dq(dq, q, K, V, O, do, m, \\\n                      stride_tok, stride_d, H, N_CTX, \\\n                      BLOCK_M2, MASK_BLOCK_N2, HEAD_DIM, \\\n                      start_m, end_n - num_steps * MASK_BLOCK_N2, num_steps, MASK=True)\n    end_n -= num_steps * MASK_BLOCK_N2\n    num_steps = end_n // BLOCK_N2\n    dq = _attn_bwd_dq(dq, q, K, V, O, do, m, \\\n                      stride_tok, stride_d, H, N_CTX, \\\n                      BLOCK_M2, BLOCK_N2, HEAD_DIM, \\\n                      start_m, end_n - num_steps * BLOCK_N2, num_steps, MASK=False)\n    dq_ptrs = DQ + offs_m[:, None] * stride_tok + offs_k[None, :] * stride_d\n    dq *= LN2\n    tl.store(dq_ptrs, dq)\n\nclass _attention(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, q, k, v, sm_scale, warp_specialize=True, USE_TMA=True):\n        HEAD_DIM_Q, HEAD_DIM_K = q.shape[-1], k.shape[-1]\n        HEAD_DIM_V = v.shape[-1]\n        assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V\n        assert HEAD_DIM_K in {16, 32, 64, 128, 256}\n        o = torch.empty_like(q)\n        M = torch.empty((q.shape[0], q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32)\n        grid = lambda args: (triton.cdiv(q.shape[2], args[\"BLOCK_M\"]), q.shape[0] * q.shape[1], 1)\n        ctx.grid = grid\n        attention_forward[grid](\n            q, k, v, sm_scale, M, o,  \\\n            q.stride(0), q.stride(1), q.stride(2), q.stride(3),  \\\n            k.stride(0), k.stride(1), k.stride(2), k.stride(3),  \\\n            v.stride(0), v.stride(1), v.stride(2), v.stride(3),  \\\n            o.stride(0), o.stride(1), o.stride(2), o.stride(3),  \\\n            q.shape[0], q.shape[1], q.shape[2],  \\\n            BLOCK_M=64,  \\\n            BLOCK_N=32,  \\\n            HEAD_DIM=HEAD_DIM_K)\n        ctx.save_for_backward(q, k, v, o, M)\n        ctx.sm_scale = sm_scale\n        ctx.HEAD_DIM = HEAD_DIM_K\n        return o\n\n    @staticmethod\n    def backward(ctx, do):\n        q, k, v, o, M = ctx.saved_tensors\n        assert do.is_contiguous()\n        assert q.stride() == k.stride() == v.stride() == o.stride() == do.stride()\n        dq = torch.empty_like(q)\n        dk = torch.empty_like(k)\n        dv = torch.empty_like(v)\n        BATCH, N_HEAD, N_CTX = q.shape[:3]\n        BLOCK_M1, BLOCK_N1, BLOCK_M2, BLOCK_N2 = 32, 64, 64, 32 # dKdV Q-seqlength-block, dKdV KV-seqlength-block, dQ Q-seqlength-block, dQ KV-seqlength-block.\n        BLK_SLICE_FACTOR = 2\n        RCP_LN2 = 1.4426950408889634\n        arg_k = k * (ctx.sm_scale * RCP_LN2)\n        PRE_BLOCK = 64\n        assert N_CTX % PRE_BLOCK == 0\n        pre_grid = (N_CTX // PRE_BLOCK, BATCH * N_HEAD)\n        grid = (N_CTX // BLOCK_N1, 1, BATCH * N_HEAD)\n        _attn_bwd[grid](\n            q, arg_k, v, ctx.sm_scale, o, do, dq, dk, dv,  \\\n            M,  \\\n            q.stride(0), q.stride(1), q.stride(2), q.stride(3),  \\\n            N_HEAD, N_CTX,  \\\n            BLOCK_M1=BLOCK_M1, BLOCK_N1=BLOCK_N1,  \\\n            BLOCK_M2=BLOCK_M2, BLOCK_N2=BLOCK_N2,  \\\n            BLK_SLICE_FACTOR=BLK_SLICE_FACTOR,  \\\n            HEAD_DIM=ctx.HEAD_DIM)\n        return dq, dk, dv, None, None, None, None\n\nattention = _attention.apply\n\ndef test_forward():\n    batch_size = 8\n    n_heads = 16\n    n_ctx = 1024\n    head_dim = 64\n    sm_scale = 0.5\n\n    q = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n    k = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n    v = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n\n    p = torch.matmul(q, k.transpose(-2, -1)) * sm_scale\n    tril = torch.tril(torch.ones((n_ctx, n_ctx), device=DEVICE))\n    p = p.masked_fill(tril == 0, float(\"-inf\"))\n    p = torch.softmax(p.float(), dim=-1).half()\n    ref_out = torch.matmul(p, v)\n\n    attn_out = attention(q, k, v, sm_scale)\n\n    close_elements = torch.isclose(ref_out, attn_out, atol=0.01, rtol=0).sum().item()\n    total_elements = ref_out.numel()\n    percentage_correct = (close_elements / total_elements) * 100\n    print(f\"Forward test: {percentage_correct:.2f}% of elements are within 0.01 (atol) of PyTorch output.\")\n    assert percentage_correct >= 99.0, f\"Forward test failed: {percentage_correct:.2f}% elements close, expected 99%\"\n    print(\"Forward test passed.\")\n\ndef test_backward():\n    batch_size = 8\n    n_heads = 16\n    n_ctx = 1024\n    head_dim = 64\n    sm_scale = 0.5\n\n    q = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n    k = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n    v = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=DEVICE, requires_grad=True)\n\n    p = torch.matmul(q, k.transpose(-2, -1)) * sm_scale\n    tril = torch.tril(torch.ones((n_ctx, n_ctx), device=DEVICE))\n    p = p.masked_fill(tril == 0, float(\"-inf\"))\n    p = torch.softmax(p.float(), dim=-1).half()\n    ref_out = torch.matmul(p, v)\n    dout = torch.randn_like(ref_out)\n    ref_out.backward(dout)\n    ref_dq = q.grad.clone()\n    ref_dk = k.grad.clone()\n    ref_dv = v.grad.clone()\n\n    q.grad = None\n    k.grad = None\n    v.grad = None\n\n    attn_out = attention(q, k, v, sm_scale)\n    attn_out.backward(dout)\n    tri_dq = q.grad.clone()\n    tri_dk = k.grad.clone()\n    tri_dv = v.grad.clone()\n\n    close_elements_dq = torch.isclose(ref_dq, tri_dq, atol=0.01, rtol=0).sum().item()\n    total_elements_dq = ref_dq.numel()\n    percentage_correct_dq = (close_elements_dq / total_elements_dq) * 100\n    print(f\"Backward test (dQ): {percentage_correct_dq:.2f}% of elements are within 0.01 (atol) of PyTorch output.\")\n    assert percentage_correct_dq >= 99.0, f\"Backward test (dQ) failed: {percentage_correct_dq:.2f}% elements close, expected 99%\"\n\n    close_elements_dk = torch.isclose(ref_dk, tri_dk, atol=0.01, rtol=0).sum().item()\n    total_elements_dk = ref_dk.numel()\n    percentage_correct_dk = (close_elements_dk / total_elements_dk) * 100\n    print(f\"Backward test (dK): {percentage_correct_dk:.2f}% of elements are within 0.01 (atol) of PyTorch output.\")\n    assert percentage_correct_dk >= 99.0, f\"Backward test (dK) failed: {percentage_correct_dk:.2f}% elements close, expected 99%\"\n\n    close_elements_dv = torch.isclose(ref_dv, tri_dv, atol=0.01, rtol=0).sum().item()\n    total_elements_dv = ref_dv.numel()\n    percentage_correct_dv = (close_elements_dv / total_elements_dv) * 100\n    print(f\"Backward test (dV): {percentage_correct_dv:.2f}% of elements are within 0.01 (atol) of PyTorch output.\")\n    assert percentage_correct_dv >= 99.0, f\"Backward test (dV) failed: {percentage_correct_dv:.2f}% elements close, expected 99%\"\n    \n    print(\"Backward test passed.\")\n\nif __name__ == \"__main__\":\n    test_forward()\n    test_backward()\n    # memory and speed benchmark\n    def measure_time_and_memory(fn, device):\n        torch.cuda.reset_peak_memory_stats(device)\n        torch.cuda.synchronize(device)\n        ms = triton.testing.do_bench(fn)\n        torch.cuda.synchronize(device)\n        peak = torch.cuda.max_memory_allocated(device)\n        return ms, peak\n\n    # setup parameters for benchmarks\n    batch_size, n_heads, n_ctx, head_dim = 1, 32, 2048, 64\n    device = torch.device(DEVICE)\n    sm_scale = 0.5\n    q = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=device, requires_grad=True)\n    k = torch.randn_like(q)\n    v = torch.randn_like(q)\n\n    def run_torch_forward():\n        p = torch.matmul(q, k.transpose(-2, -1)) * sm_scale\n        tril = torch.tril(torch.ones((n_ctx, n_ctx), device=device))\n        p = p.masked_fill(tril == 0, float(\"-inf\"))\n        p = torch.softmax(p.float(), dim=-1).half()\n        return torch.matmul(p, v)\n\n    def run_triton_forward():\n        return attention(q, k, v, sm_scale)\n\n    ms_torch, peak_torch = measure_time_and_memory(run_torch_forward, device)\n    ms_triton, peak_triton = measure_time_and_memory(run_triton_forward, device)\n    print(f\"Torch forward time: {ms_torch:.2f} ms   peak mem: {peak_torch/1024**2:.1f} MB\")\n    print(f\"Triton forward time: {ms_triton:.2f} ms   peak mem: {peak_triton/1024**2:.1f} MB\")\n\n    # benchmark backward\n    def run_torch_backward():\n        q.grad, k.grad, v.grad = None, None, None\n        out = run_torch_forward()\n        grad = torch.randn_like(out)\n        out.backward(grad)\n\n    def run_triton_backward():\n        q.grad, k.grad, v.grad = None, None, None\n        out = run_triton_forward()\n        grad = torch.randn_like(out)\n        out.backward(grad)\n\n    ms_torch_bwd, peak_torch_bwd = measure_time_and_memory(run_torch_backward, device)\n    ms_triton_bwd, peak_triton_bwd = measure_time_and_memory(run_triton_backward, device)\n    print(f\"Torch backward time: {ms_torch_bwd:.2f} ms   peak mem: {peak_torch_bwd/1024**2:.1f} MB\")\n    print(f\"Triton backward time: {ms_triton_bwd:.2f} ms   peak mem: {peak_triton_bwd/1024**2:.1f} MB\")\n\n    # Performance plots using Triton perf_report\n    configs = [\n        triton.testing.Benchmark(\n            x_names=[\"n_ctx\"], x_vals=[512, 1024, 2048, 4096],\n            line_arg=\"provider\", line_vals=[\"Torch\", \"Triton\"],\n            line_names=[\"Torch\", \"Triton\"], styles=[(\"red\",\"-\"),(\"blue\",\"-\")],\n            ylabel=\"Time (ms)\", plot_name=\"FA2 Benchmark\",\n            args={\"batch_size\": batch_size, \"n_heads\": n_heads, \"head_dim\": head_dim, \"sm_scale\": sm_scale},\n        )\n    ]\n    @triton.testing.perf_report(configs)\n    def benchmark(n_ctx, provider, batch_size, n_heads, head_dim, sm_scale):\n        device = torch.device(DEVICE)\n        q = torch.randn((batch_size, n_heads, n_ctx, head_dim), dtype=torch.float16, device=device)\n        k = torch.randn_like(q)\n        v = torch.randn_like(q)\n        def run_torch_forward():\n            p = torch.matmul(q, k.transpose(-2, -1)) * sm_scale\n            tril = torch.tril(torch.ones((n_ctx, n_ctx), device=device))\n            p = p.masked_fill(tril == 0, float(\"-inf\"))\n            p = torch.softmax(p.float(), dim=-1).half()\n            return torch.matmul(p, v)\n        def run_triton_forward():\n            return attention(q, k, v, sm_scale)\n        if provider == \"Torch\":\n            result = triton.testing.do_bench(run_torch_forward)\n        else:\n            result = triton.testing.do_bench(run_triton_forward)\n        if isinstance(result, tuple):\n            ms, min_ms, max_ms = result\n        else:\n            ms = min_ms = max_ms = result\n        return ms, min_ms, max_ms\n\n    benchmark.run(show_plots=True, print_data=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T01:06:14.823133Z","iopub.execute_input":"2025-06-21T01:06:14.823624Z","iopub.status.idle":"2025-06-21T01:06:26.713799Z","shell.execute_reply.started":"2025-06-21T01:06:14.823605Z","shell.execute_reply":"2025-06-21T01:06:26.713270Z"}},"outputs":[{"name":"stdout","text":"Forward test: 100.00% of elements are within 0.01 (atol) of PyTorch output.\nForward test passed.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"Backward test (dQ): 99.47% of elements are within 0.01 (atol) of PyTorch output.\nBackward test (dK): 99.25% of elements are within 0.01 (atol) of PyTorch output.\nBackward test (dV): 100.00% of elements are within 0.01 (atol) of PyTorch output.\nBackward test passed.\nTorch forward time: 20.27 ms   peak mem: 1596.2 MB\nTriton forward time: 0.32 ms   peak mem: 304.5 MB\nTorch backward time: 49.60 ms   peak mem: 2364.2 MB\nTriton backward time: 1.53 ms   peak mem: 344.5 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"FA2 Benchmark:\n    n_ctx      Torch    Triton\n0   512.0   0.758193  0.060559\n1  1024.0   5.267590  0.108047\n2  2048.0  20.270592  0.327330\n3  4096.0  81.714172  1.303893\n","output_type":"stream"}],"execution_count":3}]}